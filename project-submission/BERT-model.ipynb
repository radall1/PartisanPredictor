{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-29T15:54:16.010528Z","iopub.status.busy":"2024-04-29T15:54:16.010267Z","iopub.status.idle":"2024-04-29T15:54:29.091949Z","shell.execute_reply":"2024-04-29T15:54:29.091143Z","shell.execute_reply.started":"2024-04-29T15:54:16.010504Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mCanceled future for execute_request message before replies were done"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","import numpy as np\n","import random\n","import requests as rq\n","import sys\n","import io\n","from bs4 import BeautifulSoup\n","from keras.callbacks import LambdaCallback\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM\n","from tensorflow.keras.optimizers import RMSprop\n","from collections import Counter\n","import keras\n","from keras.layers import Embedding\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt # data visualization\n","import seaborn as sns # statistical data visualization\n","%matplotlib inline\n","\n","\n","\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input/SupremeCourtNew'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T15:54:29.094040Z","iopub.status.busy":"2024-04-29T15:54:29.093508Z","iopub.status.idle":"2024-04-29T15:54:29.698075Z","shell.execute_reply":"2024-04-29T15:54:29.697102Z","shell.execute_reply.started":"2024-04-29T15:54:29.094015Z"},"scrolled":true,"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>total_order</th>\n","      <th>order</th>\n","      <th>year</th>\n","      <th>nominee</th>\n","      <th>speaker_title</th>\n","      <th>speaker_party</th>\n","      <th>speaker_name</th>\n","      <th>speaker_statement</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Total Order</td>\n","      <td>Order</td>\n","      <td>Year</td>\n","      <td>Hearing</td>\n","      <td>Title</td>\n","      <td>Speaker (Party)(or nominated by)</td>\n","      <td>Speaker and title</td>\n","      <td>Statements</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2018</td>\n","      <td>Brett M. Kavanaugh</td>\n","      <td>Chairman</td>\n","      <td>R</td>\n","      <td>Senator Chuck Grassley (IA)</td>\n","      <td>Chairman GRASSLEY. I welcome everyone to this ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2018</td>\n","      <td>Brett M. Kavanaugh</td>\n","      <td>Senator</td>\n","      <td>D</td>\n","      <td>Senator Kamala Harris (CA)</td>\n","      <td>Senator HARRIS. Mr. Chairman?</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2018</td>\n","      <td>Brett M. Kavanaugh</td>\n","      <td>Chairman</td>\n","      <td>R</td>\n","      <td>Senator Chuck Grassley (IA)</td>\n","      <td>Chairman GRASSLEY [continuing]. Brett Kavanaugh</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>2018</td>\n","      <td>Brett M. Kavanaugh</td>\n","      <td>Senator</td>\n","      <td>D</td>\n","      <td>Senator Kamala Harris (CA)</td>\n","      <td>Senator HARRIS. Mr. Chairman?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   total_order  order  year             nominee speaker_title  \\\n","0  Total Order  Order  Year             Hearing         Title   \n","1            1      1  2018  Brett M. Kavanaugh      Chairman   \n","2            2      2  2018  Brett M. Kavanaugh       Senator   \n","3            3      3  2018  Brett M. Kavanaugh      Chairman   \n","4            4      4  2018  Brett M. Kavanaugh       Senator   \n","\n","                      speaker_party                 speaker_name  \\\n","0  Speaker (Party)(or nominated by)            Speaker and title   \n","1                                 R  Senator Chuck Grassley (IA)   \n","2                                 D   Senator Kamala Harris (CA)   \n","3                                 R  Senator Chuck Grassley (IA)   \n","4                                 D   Senator Kamala Harris (CA)   \n","\n","                                   speaker_statement  \n","0                                         Statements  \n","1  Chairman GRASSLEY. I welcome everyone to this ...  \n","2                      Senator HARRIS. Mr. Chairman?  \n","3    Chairman GRASSLEY [continuing]. Brett Kavanaugh  \n","4                      Senator HARRIS. Mr. Chairman?  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["data = '/kaggle/input/supremecourtnew/SupremeCourtTranscriptNew.csv'\n","df = pd.read_csv(data, header=None,encoding='latin-1')\n","col_names = ['total_order', 'order', 'year', 'nominee', 'speaker_title', 'speaker_party', 'speaker_name','speaker_statement']\n","df.columns = col_names\n","col_names\n","df.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T15:54:29.699662Z","iopub.status.busy":"2024-04-29T15:54:29.699280Z","iopub.status.idle":"2024-04-29T15:54:29.825142Z","shell.execute_reply":"2024-04-29T15:54:29.824322Z","shell.execute_reply.started":"2024-04-29T15:54:29.699610Z"},"trusted":true},"outputs":[],"source":["df['nominee'].unique()\n","df['speaker_statement'] = df['speaker_statement'].apply(lambda x: x.split('.', 1)[-1].strip())\n","df['speaker_statement'] = df['speaker_statement'].str.replace(r'\\[[^\\]]*]\\s*([^\\.]*\\.)?', '', regex=True)\n","df.loc[df['nominee'] =='Brett M. Kavanaugh II', 'nominee'] = 'Brett M. Kavanaugh'\n","df.loc[df['nominee'] =='Clarence Thomas II', 'nominee'] = 'Clarence Thomas'\n","df.loc[df['nominee'] =='Judge Robert Bork', 'nominee'] = 'Robert Bork'\n","df['nominee'].unique()\n","df['speaker_party'].unique()\n","df['speaker_party'].value_counts()\n","unaffiliated = df['speaker_party'].isnull()\n","df.loc[unaffiliated, 'speaker_party'] = 'Unaffiliated'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#This supplemental model was made in help with the resources from Hugging Face (The provider and documentation for the BERT Model), specifically:\n","#BERT Documentation: https://huggingface.co/docs/transformers/en/model_doc/bert\n","#https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\n","\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from tqdm import tqdm\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score\n","\n","speaker_statements = df['speaker_statement'].values\n","speaker_parties = df['speaker_party'].values\n","label_encoder = LabelEncoder()\n","speaker_parties_encoded = label_encoder.fit_transform(speaker_parties)\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(set(speaker_parties)))\n","\n","train_texts, val_texts, train_labels, val_labels = train_test_split(speaker_statements, speaker_parties_encoded, test_size=0.2, random_state=42)\n","\n","class SentimentDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_length):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        inputs = self.tokenizer(\n","            text,\n","            return_tensors=\"pt\",\n","            padding=\"max_length\",  #padding\n","            truncation=True,\n","            max_length=self.max_length\n","        )\n","        label = torch.tensor(self.labels[idx], dtype=torch.long)\n","        return inputs, label\n","\n","\n","train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, max_length=128)\n","val_dataset = SentimentDataset(val_texts, val_labels, tokenizer, max_length=128)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","num_epochs = 5\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","model.train()\n","for epoch in range(num_epochs):\n","    train_losses = []\n","    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n","        inputs, labels = batch\n","        inputs = {key: value.squeeze(1).to(device) for key, value in inputs.items()}  # Squeeze the extra dimension\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(**inputs, labels=labels)\n","        loss = outputs.loss\n","        train_losses.append(loss.item())\n","        loss.backward()\n","        optimizer.step()\n","    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {sum(train_losses)/len(train_losses):.4f}')\n","\n","model.eval()\n","val_losses = []\n","val_preds = []\n","val_true = []\n","for batch in val_loader:\n","    inputs, labels = batch\n","    inputs = {key: value.squeeze(1).to(device) for key, value in inputs.items()}\n","    labels = labels.to(device)\n","    with torch.no_grad():\n","        outputs = model(**inputs, labels=labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","    val_losses.append(loss.item())\n","    val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","    val_true.extend(labels.cpu().numpy())\n","\n","val_accuracy = accuracy_score(val_true, val_preds)\n","print(f\"Validation Loss: {sum(val_losses)/len(val_losses):.4f}, Validation Accuracy: {val_accuracy:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def predict_sentiment(text):\n","    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n","    inputs = {key: value.to(device) for key, value in inputs.items()}\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","    \n","    predicted_label_idx = logits.argmax(dim=1).item()\n","    predicted_label = label_encoder.classes_[predicted_label_idx]\n","    \n","    return predicted_label\n","\n","input_text = \"What is being done here is unprecedented, and I keep coming back to the same question I asked. What are we trying to hide? What are we hiding? What is being hidden?\"\n","predicted_sentiment = predict_sentiment(input_text)\n","print(\"Predicted sentiment:\", predicted_sentiment)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4788353,"sourceId":8106964,"sourceType":"datasetVersion"},{"datasetId":4855122,"sourceId":8196609,"sourceType":"datasetVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"d51ba1553ba41140e5148ee8bc598d69ba43bfdf34fcdabecdeef96c68b8c73f"}}},"nbformat":4,"nbformat_minor":4}
